from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

from scipy.ndimage.morphology import grey_closing
from scipy.ndimage.morphology import grey_dilation, grey_erosion, morphological_gradient
from scipy.ndimage.morphology import distance_transform_edt
from scipy.ndimage import find_objects
from scipy.ndimage.filters import gaussian_filter
from scipy.signal import gaussian
from scipy.ndimage.measurements import center_of_mass
from scipy.spatial.distance import cdist
from skimage.segmentation import find_boundaries
from skimage.morphology import thin, skeletonize, skeletonize_3d

from dlutils.preprocessing.normalization import min_max_scaling

import numpy as np


def generate_border_map(segmentation, border_width=1, decay=10):
    '''calculate border target map from instance segmentation.

    Notes
    -----
    Border map is a detection heatmap calculated as

     f(x) = exp( - dt(x) / decay )

    where dt(..) is the distance transform from the segmentation
    border pixels. If segmentation is an instance segmentation,
    i.e. invidual labels for each instance, then the border will
    outline different instances.

    '''
    border_width = max(border_width - 2, 0)

    boundary = find_boundaries(
        segmentation, connectivity=2, mode='thick', background=0)
    if border_width > 0:
        grey_dilation(boundary, border_width, output=boundary)
    boundary = np.logical_not(boundary)
    boundary = boundary.astype(np.float32)
    boundary = distance_transform_edt(boundary)
    boundary = np.exp(-boundary / decay)
    return boundary


def generate_separator_map(segmentation, border_width=4, decay=10, reach=25):
    '''calculate borders between foreground instances.

    Notes
    -----
    Border map is a detection heatmap calculated as

     f(x) = np.exp( - dt(x) / decay )

    where dt(..) is the distance transform from the segmentation
    border pixels. If segmentation is an instance segmentation,
    i.e. invidual labels for each instance, then the border will
    outline different instances.

    '''
    border_width = max(border_width - 2, 0)

    dist, indices = distance_transform_edt(
        segmentation == 0, return_indices=True, return_distances=True)
    closest = segmentation[indices.tolist()]

    boundary = find_boundaries(closest, connectivity=2, mode='thick')

    if border_width > 0:
        grey_dilation(boundary, border_width, output=boundary)

    # limit separators to areas close to cells.
    boundary = np.logical_and(boundary, dist <= reach)

    # turn binary separator map into heatmap
    boundary = np.logical_not(boundary)
    boundary = boundary.astype(np.float32)
    boundary = distance_transform_edt(boundary)
    boundary = np.exp(-boundary / decay)
    return boundary


def generate_masked_separator(segmentation, maskval,
                              truncate=0.1, *args, **kwargs):
    '''returns a masked version of the separator map generated by
    generate_separator_map.
    
    Notes
    -----
    The distance is individually normalized to [0,1] for each cluster.
    '''
    separator = generate_separator_map(segmentation, *args, **kwargs)
    mask = np.logical_and(segmentation == 0, separator <= truncate)
    separator[mask] = maskval
    return separator

def generate_distance_transform(segmentation, sampling=1.0, sigma=0.5):
    '''calculate the distance transform separately for each labeled 
    cluster.
    
    '''
    if not isinstance(segmentation, np.ndarray) or segmentation.dtype != int:
        raise ValueError('Expected an integer numpy.ndarray as segmentation labels, got: {}, {}'.format(
                                type(segmentation), segmentation.dtype))
    if sampling is None:
        sampling = 1.0
    
    transform = np.zeros_like(segmentation, dtype=np.float)
    for label in range(1,segmentation.max()+1):
        loc = find_objects(segmentation == label)
        if loc:
            loc = loc[0]
            # expand the slice to make sure a borders are visible when labels
            # are aligned vertically or horizontally 
            loc = tuple(slice(max(0,sli.start-1),sli.stop+1) for sli in loc)
            
            transformed_label = distance_transform_edt(segmentation[loc]==label, sampling=sampling)
            transform[loc] += min_max_scaling(transformed_label)
    
    if sigma > 0:
        transform = gaussian_filter(transform, sigma=0.5/np.asarray(sampling))
        transform = min_max_scaling(transform)
    
    return transform


def paste_slices(tup):
  pos, w, max_w = tup
  wall_min = max(pos, 0)
  wall_max = min(pos+w, max_w)
  block_min = -min(pos, 0)
  block_max = max_w-max(pos+w, max_w)
  block_max = block_max if block_max != 0 else None
  return slice(wall_min, wall_max), slice(block_min, block_max)

def paste(wall, block, loc):
  loc_zip = zip(loc, block.shape, wall.shape)
  wall_slices, block_slices = zip(*map(paste_slices, loc_zip))
  wall[wall_slices] += block[block_slices]

def generate_seed_map(segmentation, sampling=1.0, sigma=1.5):
    '''
    
    Notes
    -----
    point on skeleton closest to center mass = center
    '''
    if sampling is None:
        sampling = 1.0
    
    # TODO split help functions (gkernel, get_center, place kernel)
    
    # TODO anisotric kernel based on sampling
    # ~ kernel_size = int(sigma*4) 
    # ~ kernel_size +=  1 - kernel_size%1 # odd size  kernel
    # ~ gkern1d = gaussian(kernel_size, std=sigma)
    # ~ gkern = np.matmul(gkern1d.reshape(-1,1), gkern1d.reshape(1,-1))
    # ~ if segmentation.ndim == 3:
        # ~ gkern = np.matmul(gkern.reshape(kernel_size,kernel_size,1), gkern1d.reshape(1,1,-1))
        
    seed_map = np.zeros_like(segmentation, dtype=np.float32)
    for label in np.unique(segmentation):
        if label > 0:
            loc = find_objects(segmentation == label)[0]
            offset = np.asarray([sli.start for sli in loc])              
            # ~ #  skeleton = thin(segmentation[loc]==label)
            skeleton = skeletonize_3d(segmentation[loc]==label)
            skeleton = np.argwhere(skeleton)+offset
            center_mass = center_of_mass(segmentation[loc]==label)
            center_mass = np.asarray(center_mass) + offset
            if skeleton.shape[0] > 0: # skeletonize_3d sometimes return empty image??
                dist_to_center_mass = cdist([center_mass], skeleton, 'euclidean')
                center = skeleton[ np.argmin(dist_to_center_mass) ]#.reshape(2,1)
            else:
                center = center_mass.astype(int)
                
            # ~ paste(seed_map, gkern, tuple(center))
            seed_map[tuple(center)] = 1.
    
    seed_map = gaussian_filter(seed_map, sigma=sigma/np.asarray(sampling))
    seed_map = transform = min_max_scaling(seed_map)
        
    return seed_map
    
def generate_center_map(segmentation):
    '''split each instance in two labels: center, surround based on normalized distance transform
    '''
    
    normalization = np.zeros_like(segmentation, dtype=np.float32)
    center_map = np.zeros_like(segmentation)
    
    dist = generate_distance_transform(segmentation)
    outer = np.logical_and(dist>0.0, dist<0.5)
    
    np.putmask(segmentation, outer, -2)
    
    n_labels = 0
    for label in np.unique(segmentation):
        if label > 0:
            area = (segmentation==label).sum()
            np.putmask(normalization, segmentation==label, 1./area)
            n_labels += 1
    
    if n_labels > 1:        
        normalization = normalization / n_labels
    
    return np.stack([segmentation, normalization], axis=-1)

def generate_locationmap(shape, period=50., offset=0.):
    '''Returns a periodic intensity map encoding image location
    '''
    
    ndim = len(shape)
    if isinstance(period, (list,tuple)):
        if len(period) == 1:
            period = period*ndim
        elif len(period) != ndim:
            raise ValueError('wrong dimension of period argument, expected 1 or {}, got: {}'.format(ndim, len(period)) )
    else:
        period = (period,)*ndim
        
    if isinstance(offset, (list,tuple)):
        if len(offset) == 1:
            offset = offset*ndim
        elif len(offset) != ndim:
            raise ValueError('wrong dimension of offset argument, expected 1 or {}, got: {}'.format(ndim, len(offset)) )
    else:
        offset = (offset,)*ndim
    
    period = np.asarray(period)
    offset = np.asarray(offset)
    amplitude = (1./len(shape),)*ndim
    w = 2*np.pi/period
    phase = offset*2*np.pi/period
    
    def f1d(x, amplitude, w, phase):
        return amplitude*np.sin(x*w+phase)
        
    def f(*args):        
        return sum( f1d(*params) for params in zip(args,amplitude,w,phase) )
    
    return np.fromfunction(f, shape, dtype=np.float32)

def generate_locationmap_target(segmentation, location_map):
    '''generate target having instance wise mean intensity of location_map loss:
    
    output channels:
    ---------
    0: instance normalization
    1: instance wise mean of location_map
    '''

    normalization = np.zeros_like(segmentation, dtype=np.float32)
    n_labels = 0
    for label in np.unique(segmentation):
        # ~ if label > 0: # BACKGROUND INCLUDED !!!!!!!!!!!!!!!!
        area = (segmentation==label).sum()
        np.putmask(normalization, segmentation==label, 1./area)
        n_labels += 1
    
    if n_labels > 1:        
        normalization = normalization / n_labels
        
    location_map_mean = np.zeros_like(segmentation, dtype=np.float32)
    for label in np.unique(segmentation):
        if label > 0: 
            indices = np.argwhere(segmentation==label)
            vals = np.take(location_map, indices)
            np.putmask(location_map_mean, segmentation==label, vals.mean())
    
    return np.stack([location_map_mean, normalization], axis=-1)

def add_border_annotation(segmentation):
    '''Adds borders with label=-1 to an existing segmentation mask 
    '''
    normalization = np.zeros_like(segmentation, dtype=np.float32)
    
    # ~ for z in range(segmentation.shape[0]):
        # ~ closed_segmentation = close_segmentation(segmentation[z], 3)
        
        # ~ boundaries = find_boundaries(closed_segmentation, connectivity=closed_segmentation.ndim, mode='inner', background=0)
        # ~ dist_to_background = distance_transform_edt( closed_segmentation>0 )
        # ~ separators = np.logical_and(boundaries, dist_to_background >2)
        # ~ separators = grey_dilation(separators, 5)
        
        # ~ transition_zone = np.logical_xor(grey_erosion(segmentation[z], 3)>0, grey_dilation(segmentation[z], 3)>0)
        
        # ~ np.putmask(segmentation[z], transition_zone, -2)
        # ~ np.putmask(segmentation[z], separators, -1)
        
        # ~ n_labels = 0
        # ~ for label in np.unique(segmentation[z]):
            # ~ if label > 0:
                # ~ area = (segmentation[z]==label).sum()
                # ~ np.putmask(normalization[z], segmentation[z]==label, 1./area)
                # ~ n_labels += 1
        
        # ~ if n_labels > 1:        
            # ~ normalization[z] = normalization[z] / n_labels

        
    closed_segmentation = close_segmentation(segmentation,3)
        
    boundaries = find_boundaries(closed_segmentation, connectivity=closed_segmentation.ndim, mode='inner', background=0)
    dist_to_background = distance_transform_edt( closed_segmentation>0 )
    separators = np.logical_and(boundaries, dist_to_background >2)
    separators = grey_dilation(separators, 1)
    
    transition_zone = np.logical_xor(grey_erosion(segmentation, 9)>0, grey_dilation(segmentation, 3)>0)
    
    np.putmask(segmentation, transition_zone, -2)
    # ~ np.putmask(segmentation, separators, -1)
    
    n_labels = 0
    for label in np.unique(segmentation):
        if label > 0:
            area = (segmentation==label).sum()
            np.putmask(normalization, segmentation==label, 1./area)
            n_labels += 1
    
    if n_labels > 1:        
        normalization = normalization / n_labels
        

    return np.stack([segmentation, normalization], axis=-1)

def close_segmentation(segmentation, size, **kwargs):
    '''close holes in segmentation maps for training.

    '''
    return grey_closing(segmentation, size=size, **kwargs)
